{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9be40c-5527-4f43-9341-875651ee76be",
   "metadata": {},
   "source": [
    "# class drake::geometry::QueryObject< T >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6858526c-970e-43f6-afcc-1e9df506af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries and functions for this tutorial.\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pydrake.common import temp_directory\n",
    "from pydrake.geometry import StartMeshcat\n",
    "from pydrake.math import RigidTransform, RollPitchYaw, RotationMatrix\n",
    "from pydrake.multibody.parsing import Parser\n",
    "from pydrake.multibody.plant import AddMultibodyPlantSceneGraph\n",
    "from pydrake.systems.analysis import Simulator\n",
    "from pydrake.systems.framework import DiagramBuilder\n",
    "from pydrake.visualization import AddDefaultVisualization, ModelVisualizer\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph, DiagramBuilder, \n",
    "    FindResourceOrThrow, GenerateHtml, InverseDynamicsController, \n",
    "    MultibodyPlant, Parser, Simulator)\n",
    "from pydrake.multibody.jupyter_widgets import MakeJointSlidersThatPublishOnCallback\n",
    "import pydrake\n",
    "from pydrake import geometry\n",
    "from pydrake.math import RigidTransform, RollPitchYaw, RotationMatrix \n",
    "from pydrake.solvers import MathematicalProgram, Solve\n",
    "from pydrake.systems.jupyter_widgets import PoseSliders, WidgetSystem\n",
    "from ipywidgets import ToggleButton, ToggleButtons\n",
    "from functools import partial\n",
    "from pydrake.all import (\n",
    "    JointIndex, PiecewisePolynomial, JacobianWrtVariable,\n",
    "    eq, ge,  AutoDiffXd, SnoptSolver, IpoptSolver,  \n",
    "    AddUnitQuaternionConstraintOnPlant, PositionConstraint, OrientationConstraint\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d0ade5-41cf-4e1a-84f2-ea4b6a9a7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-3\n",
    "builder = DiagramBuilder()\n",
    "plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=h)\n",
    "parser = Parser(plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827c0c20-fd33-4201-add3-fb7a345e78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"/Users/xiao/0_codes/ICBM_drake/models/objects\"\n",
    "dir2 = \"/Users/xiao/0_codes/ICBM_drake/models/ycb/sdf/\"\n",
    "table_file = os.path.join(dir1, \"table_top.sdf\")\n",
    "panda_file = \"/Users/xiao/0_codes/ICBM_drake/models/franka_description/urdf/panda_arm_hand.urdf\"\n",
    "box_file = os.path.join(dir2, \"003_cracker_box.sdf\")\n",
    "table_modelInstance = parser.AddModels(table_file)[0]  # this return pydrake.multibody.tree.ModelInstanceIndex\n",
    "panda_modelInstance = parser.AddModels(panda_file)[0]\n",
    "box_modelInstance = parser.AddModels(box_file)[0]\n",
    "\n",
    "table_top_frame = plant.GetFrameByName(\"table_top_center\")\n",
    "robot_base = plant.GetFrameByName(\"panda_link0\")\n",
    "\n",
    "X_W_table = RigidTransform(\n",
    "  R=RotationMatrix([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],]),\n",
    "  p=[0.0, 0.0, 0.0]\n",
    ")\n",
    "\n",
    "plant.WeldFrames(plant.world_frame(), table_top_frame, X_W_table)\n",
    "plant.WeldFrames(table_top_frame, robot_base, RigidTransform(RotationMatrix.Identity(), [0., -0.4, 0.]))\n",
    "plant.Finalize()\n",
    "plant.set_name(\"table_with_box\")\n",
    "diagram = builder.Build()\n",
    "context = diagram.CreateDefaultContext()\n",
    "mutable_context = plant.GetMyContextFromRoot(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1444e-ddda-480e-a74a-ed7a5f30985a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Querying the scene geometry based on context at $t_k$:</b> 1. create mutable_contexts from root_context for each time step; 2. at $t_k$, using its corresponding mutable_context to create a query_port; 3. create query_object, which has some useful member functions; 4. create the inspector = query_object.inspector() to extract informations from the scene geometries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5028043-ed33-40ea-809b-847af3a4f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_port = plant.get_geometry_query_input_port()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e33f04e1-eabf-4be8-a4ec-0734b67bdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_port.HasValue(mutable_context):\n",
    "    query_object = query_port.Eval(mutable_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6aeed3-c39d-4d49-9adc-c5ae767bdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_distance_pairs = query_object.ComputeSignedDistancePairwiseClosestPoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aff48ae-bfb9-457a-91ad-f529aeb7677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2165\n"
     ]
    }
   ],
   "source": [
    "print(len(signed_distance_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8dab5d9-9664-43f5-a4f4-7aefa07ce3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GeometryId value=21>\n",
      "<GeometryId value=282>\n"
     ]
    }
   ],
   "source": [
    "print(signed_distance_pairs[0].id_A)\n",
    "print(signed_distance_pairs[0].id_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f5eb78-d54e-47b4-ac45-c206c98d8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the inspector to get info on the pairs\n",
    "inspector = query_object.inspector()\n",
    "frameA_id = inspector.GetFrameId(signed_distance_pairs[0].id_A)\n",
    "frameB_id = inspector.GetFrameId(signed_distance_pairs[1].id_B)\n",
    "\n",
    "bodyA = plant.GetBodyFromFrameId(frameA_id)\n",
    "bodyB = plant.GetBodyFromFrameId(frameB_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9beb68d1-f5bf-4c44-8378-008d2b9b204c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydrake.multibody.tree.RigidBody"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bodyA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17152cce-765c-4964-815e-c6964581dfd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RigidBody name='table_top_link' index=1 model_instance=2>\n",
      "<RigidBody name='base_link_cracker' index=14 model_instance=4>\n"
     ]
    }
   ],
   "source": [
    "print(bodyA)\n",
    "print(bodyB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c426d-77a4-41d3-81d2-a2ad5945b27b",
   "metadata": {},
   "source": [
    "__A variant of ComputeSignedDistancePairwiseClosestPoints() which computes the signed distance (and witnesses) between a specific pair of geometries indicated by id.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e6ab1be-2348-4acb-aad1-14278c325006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This could be used for getting pairs between finger and box\n",
    "query_object.ComputeSignedDistancePairClosestPoints(GeometryId geometry_id_A,\n",
    "                                                    GeometryId geometry_id_B)\n",
    "\"\"\"                                                     \"\"\"\n",
    "# maybe use this \n",
    "query_object.ComputeSignedDistanceToPoint()\n",
    "\"\"\"\n",
    "\n",
    "# get link 7 in {W}\n",
    "link7_frame = plant.GetFrameByName(\"panda_link7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35cd9d79-236d-4f46-90f5-b2c2415eb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BodyFrame name='panda_link7' index=11 model_instance=3>\n"
     ]
    }
   ],
   "source": [
    "print(link7_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdaeb9e2-f44b-4e11-92d8-ce75645fee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RigidTransform(\n",
       "  R=RotationMatrix([\n",
       "    [1.0, 0.0, 0.0],\n",
       "    [0.0, 1.0, 0.0],\n",
       "    [0.0, 0.0, 1.0],\n",
       "  ]),\n",
       "  p=[0.0, 0.0, 0.0],\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link7_frame.CalcPoseInBodyFrame(mutable_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dcea77a-81d0-44ef-86a9-f23f081c58b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RigidTransform(\n",
       "  R=RotationMatrix([\n",
       "    [1.0, 0.0, 0.0],\n",
       "    [0.0, -1.0, -9.793177720293495e-12],\n",
       "    [0.0, 9.793177720293495e-12, -1.0],\n",
       "  ]),\n",
       "  p=[0.088, -0.39999999999966707, 1.033],\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link7_frame.CalcPoseInWorld(mutable_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941e45a-0057-4d9a-b96d-e50f5ba39478",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>I know what to do next!!:</b> Manually choose a point on the finger in {link8}. Then manually choose three points of the box to give surface normal. Something useful relevant to contact constraints: https://drake.mit.edu/doxygen_cxx/group__contact__surface__constraints.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf123e-d9c9-4767-81b7-f4114bfcc7e6",
   "metadata": {},
   "source": [
    "__this will be useful!__ #include \"drake/geometry/proximity/calc_distance_to_surface_mesh.h\" and \"proximity_utilities.h\" These are what I will be doing manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96fa350d-83e1-4d7f-bc63-c38dcd7b269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box fram in W: RigidTransform(\n",
      "  R=RotationMatrix([\n",
      "    [1.0, 0.0, 0.0],\n",
      "    [0.0, 1.0, 0.0],\n",
      "    [0.0, 0.0, 1.0],\n",
      "  ]),\n",
      "  p=[0.0, 0.0, 0.0],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "box_frame = plant.GetFrameByName(\"base_link_cracker\")\n",
    "print(f\"box fram in W: {box_frame.CalcPoseInWorld(mutable_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a866e931-6679-4b93-b03c-a175fa8f3a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInstanceIndex(3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_modelInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1816b28-2985-48e0-ac60-39ad49fcea82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BodyFrame name='world' index=0 model_instance=0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant.world_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "818a7d78-d66b-40dd-8d08-9c18247f9c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RigidTransform(\n",
       "  R=RotationMatrix([\n",
       "    [1.0, 0.0, 0.0],\n",
       "    [0.0, 1.0, 0.0],\n",
       "    [0.0, 0.0, 1.0],\n",
       "  ]),\n",
       "  p=[0.0, 0.0, 0.0],\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant.world_frame().CalcPoseInWorld(mutable_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "20e3fe7d-60b9-4ae7-bc27-b83470ccfeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0795,  0.1042,  0.0334],\n",
       "       [ 0.0795, -0.1042,  0.0334],\n",
       "       [-0.0795,  0.1042,  0.0334],\n",
       "       [-0.0795, -0.1042,  0.0334],\n",
       "       [ 0.0795,  0.1042, -0.0334],\n",
       "       [ 0.0795, -0.1042, -0.0334],\n",
       "       [-0.0795,  0.1042, -0.0334],\n",
       "       [-0.0795, -0.1042, -0.0334]])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" a function to extract collision points from the box\n",
    "    These points are expressed in {box}\n",
    "\"\"\"\n",
    "def getPointsFromCollisionBox(modelfile):\n",
    "    points = []\n",
    "    with open(modelfile, 'r') as f:\n",
    "        model_file = f.read()\n",
    "    model_data = bs(model_file, \"xml\")\n",
    "    box_collision_points = model_data.find_all('collision') # this gathers all <collision> tags in the model.\n",
    "    # print(box_collision_points)\n",
    "    for ele in box_collision_points:\n",
    "        if ele[\"name\"].split('_')[0] == \"point\":\n",
    "            coords = ele.text.strip().split(' ')\n",
    "            points.append([coords[0], coords[1], coords[2]])\n",
    "    return np.array(points).astype(float)\n",
    "    \n",
    "vertices = getPointsFromCollisionBox(box_file)\n",
    "vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9efdb0-7f9d-4443-a903-88aa4b01cd10",
   "metadata": {},
   "source": [
    "__Now I can compute the surfaces normal, then project a point in hand onto the surface.__\n",
    "__Next up: get a point in left finger, then express in {W}__\n",
    "__Then, compute the relative velocity at contact point {C}__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7072b104-a368-4f07-949f-152a04a8d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A point of the right finger expressed in panda_link7 is:\n",
      " [[-0.00494975]\n",
      " [-0.00494975]\n",
      " [ 0.2104    ]]\n"
     ]
    }
   ],
   "source": [
    "# get the transformation from {rightfinger} to {link7}\n",
    "rightfinger_frame = plant.GetFrameByName(\"panda_rightfinger\")\n",
    "link7_frame = plant.GetFrameByName(\"panda_link7\")\n",
    "X_w_rightfinger = rightfinger_frame.CalcPoseInWorld(mutable_context)\n",
    "X_w_link7 = link7_frame.CalcPoseInWorld(mutable_context)\n",
    "X_link7_p = X_w_link7.inverse().multiply(X_w_rightfinger)\n",
    "\n",
    "# from the urdf collision bodies get a roughly exstimated points, express in {link7}\n",
    "p_rf = np.array([[0], [-0.007], [0.045]])\n",
    "p_link7_rf = X_link7_p.multiply(p_rf)\n",
    "print(f\"A point of the right finger expressed in panda_link7 is:\\n {p_link7_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "be2236c1-02a9-4a2e-923e-7b3c6b15863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameIds = inspector.GetAllFrameIds()\n",
    "# plant.GetBodyFromFrameId(frameIds)\n",
    "def getFrameIdByLinkName(linkName, frameIds):\n",
    "    for id in frameIds:\n",
    "        if plant.GetBodyFromFrameId(id).name() == linkName:\n",
    "            return id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8480d32-cacd-472b-bf15-4b47dd4f891b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Just realized!!:</b> I should not rigidly follow the C++ sliding_friction_complementarity_constraint.cc line 211-216. Because in Drake's pipeline, the contact points are detected by SceneGraph(), which are registered as points in the colliding geometries. Then it makes sense to transform the points into body frame. I can just do this manually as I know the contacts in bodies and their poses. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0929cfc-bde1-489d-8bc8-ad96bfc5e099",
   "metadata": {},
   "source": [
    "# Continue here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b6201ba8-baf6-4d84-af46-02ba76ef23ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00494975],\n",
       "       [ 0.00494975],\n",
       "       [-0.045     ]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# micmicing line 211-221 in sliding_fricition_complementarity_constraint.cc\n",
    "pA_in_geom_finger = np.array([[0], [-0.007], [0.045]])\n",
    "rightfinger_frameId = getFrameIdByLinkName(\"panda_rightfinger\", frameIds)\n",
    "rightfinger_pose = rightfinger_frame.CalcPoseInBodyFrame(mutable_context)\n",
    "pA_in_rightfinger_frame = rightfinger_pose @ pA_in_geom_finger\n",
    "pA_in_w_1 = plant.CalcRelativeTransform(mutable_context, plant.world_frame(), rightfinger_frame).rotation() @ pA_in_rightfinger_frame\n",
    "pA_in_w_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0ef47c16-867b-4509-8dcf-d730d3e61740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns the surface normals of a geometry expressed in {W}\n",
    "def getNormalsOfBoxInGeom(vertices):\n",
    "    \"\"\"\n",
    "    Top surface is indexed as (clockwise): 0, 1, 3, 2\n",
    "    bottom surface (clockwise): 4, 5, 7, 6\n",
    "    \"\"\"\n",
    "    # edges from vertices from far corners, common at index 0. \n",
    "    # the edges are: 01, 04, 02.\n",
    "    edge01 = vertices[1] - vertices[0]\n",
    "    edge04 = vertices[4] - vertices[0]\n",
    "    edge02 = vertices[2] - vertices[0]\n",
    "    \n",
    "    # edges from vertices, common at index 7. \n",
    "    # the edges are: 75, 76, 73\n",
    "    edge75 = vertices[5] - vertices[7]\n",
    "    edge76 = vertices[6] - vertices[7]\n",
    "    edge73 = vertices[3] - vertices[7]\n",
    "    \n",
    "    # get normals using edges (right hand rule, cross product). surface normals always go outwards\n",
    "    normals = np.zeros((6, 3))\n",
    "    normals[0, :] = np.cross(edge04, edge01)/np.linalg.norm(np.cross(edge04, edge01)) # surface 04x01\n",
    "    normals[1, :] = np.cross(edge04, edge02)/np.linalg.norm(np.cross(edge04, edge02)) # surface 04x02\n",
    "    normals[2, :] = np.cross(edge02, edge01)/np.linalg.norm(np.cross(edge02, edge01)) # surface 02x01\n",
    "    normals[3, :] = np.cross(edge75, edge73)/np.linalg.norm(np.cross(edge75, edge73)) # surface 75x73\n",
    "    normals[4, :] = np.cross(edge76, edge75)/np.linalg.norm(np.cross(edge76, edge75)) # surface 76x75\n",
    "    normals[5, :] = np.cross(edge73, edge76)/np.linalg.norm(np.cross(edge73, edge76)) # surface 73x76\n",
    "\n",
    "    return normals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f0ac6-36ee-4af5-9c93-e1c2f5c5bc83",
   "metadata": {},
   "source": [
    "__Pay special attention here that only the rotation part is used. Because we need to know the contact point Cb (or the witness point) orientation in the current link frame expressed in {W}. Drake's pipline detects contact points using .inspector() in SceneGraph() which produce the contacts in pairs of contact bodies by pydrake.geometry.SignedDistancePair() class. Each body in the pair is referenced using GeometryId and the witness point coordinats is respecting the Geometry frame (NOT the current body frame!!). Then current body frame is required to transform the point to body frame using only the rotation is needed because the both frames are at the same location but different orientations. In other words, we want it to rotate in place.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "32cc8a9b-30ac-4059-b235-df107f8815ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as in last block\n",
    "pCb_in_rightfinger = np.array([[0], [-0.007], [0.045]])\n",
    "rightfinger_pose = rightfinger_frame.CalcPoseInWorld(mutable_context)\n",
    "p_rfCb_in_w = rightfinger_pose.rotation() @ pCb_in_rightfinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "769d35ea-08f7-4af7-93da-b82acc18f084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get spatial velocity of right finger measured in box frame, expressed in {W}\n",
    "V_box_rf_w = rightfinger_frame.CalcSpatialVelocity(mutable_context, box_frame, plant.world_frame())\n",
    "\n",
    "# v_box_Cb_W is the sliding velocity of witness point Cb measured from the box, expressed in the world frame.\n",
    "v_box_Cb_w = V_box_rf_w.Shift(p_rfCb_in_w).translational();\n",
    "v_box_Cb_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c5bf1-18a9-4044-a15e-406004da1a12",
   "metadata": {},
   "source": [
    "__choosing an arbitrary surface for the time being. Later maybe choosing the closest one.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "d0a9e8fa-e87c-47ff-9971-b0b4ffb12717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, project the sliding velocity v_box_Cb_W to the tangential plane. \n",
    "Then need to know the surface normal, nhat_box_Cb_w. \"\"\"\n",
    "#nhat_BA_W = signed_distance_pair.nhat_BA_W;\n",
    "#const Vector3<AutoDiffXd> v_sliding_ACb_W = (Eigen::Matrix3d::Identity() - nhat_BA_W * nhat_BA_W.transpose()) * v_ACb_W;\n",
    "nhats = getNormalsOfBoxInGeom(vertices) # nhats in {body} frame\n",
    "\n",
    "# Now we are arbitrarily choosing a surfce to work with for the time being.\n",
    "nhat_box_to_finger = nhats[0]\n",
    "\n",
    "# express the normal in {b} in {s}\n",
    "nhat_box_to_finger_w =  box_frame.CalcPoseInWorld(mutable_context).rotation() @ nhat_box_to_finger\n",
    "\n",
    "# projecting the sliding velocity onto the contact tangential plane (here one of the surface of the box)\n",
    "v_sliding_box_Cb_w = v_box_Cb_w - np.dot(v_box_Cb_w, nhat_box_to_finger_w) * nhat_box_to_finger_w\n",
    "v_sliding_box_Cb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d96b94-965d-4d9a-8220-94d217282f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
